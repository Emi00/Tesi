{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appunti sulla tesi *ottimizzazione degli algoritmi di ordinamento utilizzando AVX512*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premesse:\n",
    "- Tutte le prove vengono eseguite sul processore AMD Ryzen 5 *7640U*\n",
    "- I computer utilizzato è un framework 13 con 16Gb di RAM con velocità 5600 MT/s\n",
    "- Il codice è compilato utilizzando sempre la flag `-march=znver5` per sfruttare tutte le potenzialità del processore\n",
    "- Kernel: 6.11.11-1-MANJARO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leggiamo le istruzioni ASM di bubbleSort e selectionSort compilate con varie opzioni:\n",
    "Per comodità utilizzo [godbolt](https://godbolt.org/) per leggere le istruzioni ASM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BubbleSort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void bubbleSort(double * v, int n) {\n",
    "    for(int i = n - 1 ; i >= 0 ; i--) {\n",
    "        for(int j = 0 ; j < i ; j++) {\n",
    "            if(v[j] > v[j+1]) {\n",
    "                std::swap(v[j],v[j+1]);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- senza parametri (standard -O0): utilizza i registri principali (rax,rdx,rcx) e traduce ~ 1:1 il codice in c, lungo circa 200 istruzioni\n",
    "- -O1: analogo a prima, ma lungo circa 30 istruzioni\n",
    "- -O2: come con `-O1` ma utilizza i registri xmm e l'istruzione `pshufd` per velocizzare le comparazioni, circa 23 istruzioni\n",
    "- -O3: identico a `-O2`, nessuna differenza\n",
    "- aggiungendo **#pragma GCC target(\"avx512f,avx512dq,avx512cd,avx512bw,avx512vl,avx512vbmi,avx512ifma,avx512pf,avx512er,avx5124fmaps,avx5124vnniw,avx512bitalg,avx512vp2intersect\") #include <immintrin.h>** per cercare di spingere l'utilizzo di AVX512 i risultati non cambiano per `-O1, -O2, -O3`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SelectionSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void selectionSort(double * v, int dim) {\n",
    "    for(int i = 0 ; i < dim ; i++) {\n",
    "        int idx = i;\n",
    "        for(int j = i + 1 ; j < dim ; j++) {\n",
    "            if(v[j] < v[idx]) {\n",
    "                idx = j;\n",
    "            }\n",
    "        }\n",
    "        swap(v[i],v[idx]);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Senza parametri (standard -O0): utilizza i registri principali e traduce ~1:1, ~80 istruzioni\n",
    "- -O1: utilizza anche registri come r9/r10/r11, sempre 1:1, ~50 istruzioni\n",
    "- -O2: come `-O1` ma ~30 istruzioni\n",
    "- -O3: identico a `-O2`, nessuna differenza\n",
    "- aggiungendo **#pragma GCC target(\"avx512f,avx512dq,avx512cd,avx512bw,avx512vl,avx512vbmi,avx512ifma,avx512pf,avx512er,avx5124fmaps,avx5124vnniw,avx512bitalg,avx512vp2intersect\") #include <immintrin.h>** per cercare di spingere l'utilizzo di AVX512 i risultati non cambiano per `-O1, -O2, -O3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountingSort\n",
    "```\n",
    "void countingSort(int * v, int n) {\n",
    "    int a = v[0];\n",
    "    int b = v[0];\n",
    "    for(int i = 0 ; i < n ; i++) {\n",
    "        a = std::max(a,v[i]);\n",
    "        b = std::min(b,v[i]);\n",
    "    }\n",
    "    int counts[a-b+1];\n",
    "    for(int i = 0 ; i < a-b+1 ; i++) {\n",
    "        counts[i] = 0;\n",
    "    }\n",
    "    for(int i = 0 ; i < n ; i++) {\n",
    "        counts[v[i]-b]++;\n",
    "    }\n",
    "    int idx = 0, i = 0;\n",
    "    while(idx < a-b+1) {\n",
    "        if(counts[idx] != 0) {\n",
    "            v[i++] = idx+b;\n",
    "            counts[idx]--;\n",
    "        } else {\n",
    "            idx++;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "*inserito il limite per ogni variabile a 240000*\n",
    "- Senza parametri (-O0): utilizza i registri principali e traduce ~1:1, ~150 istruzioni\n",
    "- -O1: utilizza nache r8/r9, ~80 istruzioni\n",
    "- -O2: utilizza anche r10+, ~90 istruzioni\n",
    "- -O3: utilizza i registri xmm, ~170 istruzioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tabella tempi, utilizzata la libreria fatta da Sansone(?) \"timer.cpp\"\n",
    "\n",
    "tempi presi in maniera non rigorosa, utilizzati per fare una prima scrematura, su un array di 1000 valori interi generati con funzione rand(), massimo INT_MAX, con 1000 prove\n",
    "\n",
    "|parametri | bubbleSort | selectionSort | insertionSort | countingSort | \n",
    "|---|---|---|---|---|\n",
    "| default (-O0) | 1125±283 | 534±195 | 757±230 |\n",
    "| -O1 | 349±150 | 275±114 | 454±157 |\n",
    "| -O2 | 1558±264 | 275±116 | 380±156 |\n",
    "| -O3 | 1559±256 | 279±122 | 441±178 |\n",
    "| -O0 + pragma | 1118±247 | 545±202 | 406±156 | 756±210 |\n",
    "| -O1 + pragma| 337±135 | 276±114 | 90±41 | 469±152 |\n",
    "| -O2 + pragma| 372±160 | 275±109 | 79±36 | 376±132 |\n",
    "| -O3 + pragma| 370±156 | 276±118 | 76±34 |456±166 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizzando intrinsics\n",
    "Come visto precedentemente il compilatore sfrutta i registri AVX solo per velocizzare le comparazioni tra 2 elementi, non sfruttando le potenzialità delle istruzioni SIMD.\n",
    "Adesso scrivo il codice con le intrinsics SIMD prese da [Intel® Intrinsics Guide](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SelectionSort\n",
    "Iniziamo dall'algoritmo che promette un miglioramento maggiore\n",
    "Da ora in avanti tutti i test sono fatti con parametri -O1, -O2 e -O3 perchè -O0 dà sempre SIGSEGV alle versioni vettorizzate (perchè era presente una load_ e non loardu_, adesso è stato sistemato)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho scritto due versioni del selectionSort ricercando le funzioni necessarie su [Intel® Intrinsics Guide](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html) per utilizzare istruzioni AVX512.\n",
    "\n",
    "La prima versione è molto simile al selectionSort senza istruzioni SIMD ma fa paragoni di 8 variabili alla volta e se trova un nuovo minimo cerca elemento per elemento a quale indice si trova.\n",
    "\n",
    "La seconda versione ha la stessa struttura, ma riduce il tempo di esecuzione evitando di fare un ciclo per trovare l'indice, ma utilizzando un algoritmo branchless che sfrutta istruzioni SIMD.\n",
    "\n",
    "Per trovare gli indici esegue una maskz_abs (non ho trovato nessuna funzione che eseguisse soltato una maschera) lasciando nel registro *c* solo gli indici dei valori minimi correnti. A questo punto mi basta uno qualsiasi dei valori diversi da zero rimasti nel registro *c*, utilizzo quindi una reduce_max che restituisce il massimo.\n",
    "\n",
    "Mi aspetto che esistano intrinsics più efficienti, ma al momento è comunque più che sufficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void selectionSortAVX512_v1(double * v, int dim) {\n",
    "    __m512d arr;\n",
    "    for(int i = 0 ; i < dim ; i++) {\n",
    "        double minimum = v[i];\n",
    "        double lastMin = minimum;\n",
    "        int idx = i;\n",
    "        int j = i;\n",
    "        while(j <= dim - 8) {\n",
    "            arr = _mm512_loadu_pd(&v[j]);\n",
    "            minimum = min(minimum,_mm512_reduce_min_pd(arr));\n",
    "            if(minimum != lastMin) {\n",
    "                lastMin = minimum;\n",
    "                for(int k = 0 ; k < 8 ; k++) {\n",
    "                    if(v[j+k] == minimum) {\n",
    "                        idx = j+k;\n",
    "                        break;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            j += 8;\n",
    "        }\n",
    "        // use regular code to check the last values with index not multiple of 8\n",
    "        while(j < dim) {\n",
    "            if(v[j] < v[idx]) {\n",
    "                idx = j;\n",
    "            }\n",
    "            j++;\n",
    "        }\n",
    "        swap(v[i],v[idx]);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void selectionSortAVX512_v2(double * v, int dim) {\n",
    "    __m512d arr,min_vect;\n",
    "    long idxs_arr[8] = {0,1,2,3,4,5,6,7};\n",
    "    __m512i c,idxs_vect = _mm512_loadu_epi64(idxs_arr);\n",
    "    __mmask8 mask;\n",
    "    for(int i = 0 ; i < dim ; i++) {\n",
    "        double minimum = v[i];\n",
    "        double last = minimum;\n",
    "        int idx = i;\n",
    "        int j = i;\n",
    "        while(j <= dim - 8) {\n",
    "            arr = _mm512_loadu_pd(&v[j]);\n",
    "            minimum = min(minimum,_mm512_reduce_min_pd(arr));\n",
    "            if(minimum != last) {\n",
    "                last = minimum;\n",
    "                min_vect = _mm512_set1_pd(minimum);\n",
    "                mask = _mm512_cmpeq_pd_mask(arr,min_vect);\n",
    "                c = _mm512_maskz_abs_epi64(mask,idxs_vect);\n",
    "                idx = j + _mm512_reduce_max_epi64(c);\n",
    "            }\n",
    "            j+=8;\n",
    "        }\n",
    "        // use regular code to check the last values with index not multiple of 8\n",
    "        while(j < dim) {\n",
    "            if(v[j] < v[idx]) {\n",
    "                idx = j;\n",
    "            }\n",
    "            j++;\n",
    "        }\n",
    "        swap(v[i],v[idx]);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerazioni\n",
    "Premessa\n",
    "\n",
    "Ho testato le 3 versioni di *selectionSort* con array di dimensione 10,100,1000,10000 e 100000. Per ogni dimensione ho compilato sia con *-O1*, *-O2*, *-O3* (per tutti ho utilizzato *-march=znver5*). Per ognuno ho provato sia con la versione 0(senza SIMD),1 e 2 dell'algoritmo. Ogniuno è stato testato con array in ordine casuale, crescente e decrescente. Per ogni combinazione ho eseguito 20 volte per avere un sample size minimo.\n",
    "\n",
    "## Osservazioni \n",
    "- La flag *-O1* è quella che rende la versione *v0* $\\textrm{consistentemente}^{1}$ più rapido\n",
    "- La flag *-O3* è quella che rende la versione *v1* $\\textrm{consistentemente}^{1}$ (ma minimamente) più lento\n",
    "- Non ci sono sostanziali differenze tra *-O1*, *-O2* e *-O3* utilizzando la versione *v2*\n",
    "- Per array di dimensione 10 i valori sono troppo ravvicinati per ricavarne considerazioni\n",
    "- Per array di dimensione 100 si inizia a notare che il caso in cui i dati sono generati in ordine decrescente impiegano $\\textrm{consistentemente}^{2}$ meno tempo di quelli in cui sono inseriti in ordine casuale, ma non si apprezza differenze tra le versioni dell'algoritmo\n",
    "- A partire da array di dimensione 1000 si nota che qualsiasi versione risulta consistentemente più rapida se eseguita su array ordinati in modo decrescente che in modo casuale (ipotizzo sia dovuto alla branch prediction del processore)\n",
    "- Per array di dimensione 1000  notiamo che *v1* è il 13,6%$^{3}$ più veloce di *v0*, mentre *v2* lo è il 31,6%$^{3}$.\n",
    "\n",
    "Note:\n",
    "1. Per ogni lunghezza testata e per ogni ordinamento iniziale dell'array\n",
    "2. Per ogni lunghezza testata\n",
    "3. compilando tutto con flag *-O1* e utilizzando la mediana dei tempi impiegati per ordinare un array di numeri generati casualmente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altre versioni\n",
    "Ho deciso di scrivere le mie versioni dell'algoritmo prima di fare di cerche per evitare di essere influenzato da algoritmi altrui.\n",
    "Cercando su internet non si trovano versioni di facile lettura, ma utilizzando i principali tool di assistenza alla programmazione possimamo ottenere alcuni spunti.\n",
    "- *ChatGPT*, anche dopo alcuni $\\textrm{solleciti}^{1}$, non restituisce un codice che esegue come richiesto.\n",
    "- *Microsoft copilot* restituisce un codice che esegue come richiesto e che, sfruttando instrinsics di cui non ero a conoscenza.\n",
    "\n",
    "Si osserva che la versione di *copilot* non necessita di un ciclo per gli ultimi massimo 7 valori, questo è dovuto alla prima condizione dell'if più interno.\n",
    "\n",
    "Note:\n",
    "1. Per solleciti sis intende messaggi in cui si precisa quale parte del codice correggere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void selectionSortAVX512_copilot(double* arr, int n) {\n",
    "    __m512d current_min_vals;\n",
    "    __mmask8 mask;\n",
    "    __m512d current_vals;\n",
    "    for (int i = 0; i < n - 1; ++i) {\n",
    "        int min_idx = i;\n",
    "        double min_val = arr[i];\n",
    "\n",
    "        for (int j = i + 1; j < n; j += 8) {\n",
    "            __m512d current_vals = _mm512_loadu_pd(&arr[j]);\n",
    "            __m512d current_min_vals = _mm512_set1_pd(min_val);\n",
    "            __mmask8 mask = _mm512_cmplt_pd_mask(current_vals, current_min_vals);\n",
    "            if (mask) {\n",
    "                // Extract the new minimum value from current_vals\n",
    "                for (int k = 0; k < 8; ++k) {\n",
    "                    if (j + k < n && (mask & (1 << k))) {\n",
    "                        if (arr[j + k] < min_val) {\n",
    "                            min_val = arr[j + k];\n",
    "                            min_idx = j + k;\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Swap the found minimum element with the first element\n",
    "        if (min_idx != i) {\n",
    "            std::swap(arr[i], arr[min_idx]);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// per completezza\n",
    "void selectionSortAVX512_ChatGPT(double* arr, size_t size) {\n",
    "    for (size_t i = 0; i < size; ++i) {\n",
    "        size_t min_index = i;\n",
    "        double min_val = arr[i];\n",
    "\n",
    "        // Find the minimum in the remaining array using AVX-512\n",
    "        for (size_t j = i; j + 8 <= size; j += 8) {\n",
    "            // Load 8 elements into an AVX-512 register\n",
    "            __m512d reg = _mm512_loadu_pd(&arr[j]);\n",
    "\n",
    "            // Compare and find the minimum value in the register\n",
    "            __mmask8 cmp_mask = _mm512_cmp_pd_mask(reg, _mm512_set1_pd(min_val), _CMP_LT_OQ);\n",
    "\n",
    "            // Update min_val and min_index directly using intrinsics\n",
    "            if (cmp_mask) {\n",
    "                // prende il primo, non funziona\n",
    "                int first_true = _tzcnt_u32(cmp_mask); // Get the index of the first true comparison\n",
    "                min_val = arr[j + first_true];\n",
    "                min_index = j + first_true;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Check any remaining elements not fitting in an AVX-512 register\n",
    "        for (size_t j = (size / 8) * 8; j < size; ++j) {\n",
    "            if (arr[j] < min_val) {\n",
    "                min_val = arr[j];\n",
    "                min_index = j;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Swap the found minimum with the current element\n",
    "        if (min_index != i) {\n",
    "            std::swap(arr[i], arr[min_index]);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Osservazioni\n",
    "La versione *copilot* è sostanzialmente equivalente alla *v2*$^{1}$ per array di dimensione 1000, mentre al crescere della dimensione degli array aumenta il distacco a suo favore. Questo è dovuto al fatto che il codice tra il secondo for e l'if successivo è molto più efficiente dell'analoga parte di *v2*. Tuttavia la parte interna al suddetto if è più rapida nella versione *v2*.\n",
    "\n",
    "Unendo le due versioni otteniamo la versione *v5*.\n",
    "\n",
    "Note:\n",
    "1. per array non ordinati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void selectionSortAVX512_v5(double * v, int dim) {\n",
    "    __m512d arr,min_vect;\n",
    "    long idxs_arr[8] = {0,1,2,3,4,5,6,7};\n",
    "    __m512i c,idxs_vect = _mm512_loadu_epi64(idxs_arr);\n",
    "    __mmask8 mask;\n",
    "    for(int i = 0 ; i < dim ; i++) {\n",
    "        double minimum = v[i];\n",
    "        double last = minimum;\n",
    "        int idx = i;\n",
    "        int j = i + 1;\n",
    "        min_vect = _mm512_set1_pd(minimum);\n",
    "        while(j < dim -8) {\n",
    "            arr = _mm512_loadu_pd(&v[j]);\n",
    "            mask = _mm512_cmplt_pd_mask(arr, min_vect);\n",
    "            if(mask) {\n",
    "                minimum = _mm512_reduce_min_pd(arr);\n",
    "                min_vect = _mm512_set1_pd(minimum);\n",
    "                mask = _mm512_cmpeq_pd_mask(arr,min_vect);\n",
    "                c = _mm512_maskz_abs_epi64(mask,idxs_vect);\n",
    "                idx = j + _mm512_reduce_max_epi64(c);\n",
    "            }\n",
    "            j+=8;\n",
    "        }\n",
    "        while(j < dim) {\n",
    "            if(v[j] < v[idx]) {\n",
    "                idx = j;\n",
    "            }\n",
    "            j++;\n",
    "        }\n",
    "        swap(v[i],v[idx]);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con array di lunghezza 1000 questa versione compilata con la flag *-O1* risulta la più lenta con uno scarto del 6.8%, tuttavia all'aumentare della lunghezza la differenza diventa sempre più insignificante.\n",
    "\n",
    "Su array di dimensione 1000 questa versione è il 29.2%$^{2}$ più veloce delle versioni *v2* e *copilot*, mentre è il 51.7% più veloce della versione *v0*\n",
    "\n",
    "All'aumentare della dimensione la versione *copilot* si avvicina sempre di più, perché la parte di codice che le distingue viene eseguita meno $\\textrm{volte}^{3}$\n",
    "\n",
    "Note:\n",
    "1. Su array con valori casuali\n",
    "2. Statistica calcolata su 100 esecuzioni con array di elementi casuali casuali\n",
    "3. Possiamo notarlo anche con la differenza tra le versioni *v1* e *v2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eseguendo un test estensivo ho notato una estrema differenza tra le statistiche degli algoritmi compilati con la flag *-O1* e gli altri(quasi il doppio nel tempo di esecuzione), quindi ho deciso di eseguire nuovamente i test ma lasciando al computer più spazio per aspirare l'aria, sperando sia sufficiente. Altrimenti sarò costtretto ad eseguire un carico molto elevato prima in modo da avere il processore in thermal protection durante tutti i test.\n",
    "pare abbia trovato un equilibrio intorno ai 65/66 gradi\n",
    "\n",
    "Purtroppo avere più spazio non è stato sufficiente, quindi ho deciso di eseguire test solo sulle parti che voglio comparare al momento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi compilato\n",
    "\n",
    "Analizziamo adesso come viene compilato il codice, per qeusta analisi utilizzerò la flag -O1, poichè le intrinsics vengono compilate nello stesso modo per tutti i livelli di ottimizzazione (da controllare).\n",
    "\n",
    "\n",
    "|riga c++|intrinsic|riga asm|istruzione asm|significato|\n",
    "|------|------|------|------|------|\n",
    "|4|_mm512_loadu_epi64|26|vmovdqa64 zmm0, addr| move data from address to register|\n",
    "|11|_mm512_set1_pd|278|vmovsd xmm4,addr|move data from address to register|\n",
    "|11|_mm512_set1_pd|285|vbroadcastsd zmm1,xmm4|extend data from register to register|\n",
    "|13|_mm512_loadu_pd|61|vmovupd zmm0,addr|move data from address to register|\n",
    "|14|_mm512_cmplt_pd_mask|68|vcmpltpd k0,zmm0,zmm1| compare less-than and output in mask|\n",
    "|16|_mm512_reduce_min_pd|81|vextractf64x4 ymm2, zmm0, 1| set ymm2[i] = zmm0[i+4] for i=0..3|\n",
    "|16|_mm512_reduce_min_pd|88|vminpd ymm2, ymm2, ymm0 | set ymm2[i] = min(ymm2[i],ymm0[i])|\n",
    "|16|_mm512_reduce_min_pd|92|vextractf64x2 xmm1, ymm2, 1 |set xmm1[i] = ymm2[i+2] for i=0,1|\n",
    "|16|_mm512_reduce_min_pd|99|vminpd xmm1, xmm1, xmm2|set xmm1[i] = min(xmm2[i],xmm1[i])|\n",
    "|17|_mm512_set1_pd|113|vbroadcastsd zmm1, xmm1|extend data from register to register|\n",
    "|18|_mm512_cmpeq_pd_mask|119|vcmpeqpd k1, zmm0, zmm1|compare equal and output mask|\n",
    "|19|_mm512_maskz_abs_epi64|126|vpabsq zmm0 {k1} {z}, zmm3| zmm0 = abs(zmm3[i]) if k1[i] for i=0..7|\n",
    "|20|_mm512_reduce_max_epi64|132|vshufi64x2 zmm2, zmm0, zmm0, 0x4e|~ set ymm2[i] = zmm0[i+4] for i=0..3|\n",
    "|20|_mm512_reduce_max_epi64|139|vpmaxsq zmm0, zmm0, zmm2|zmm0[i] = max(zmm0[i],zmm2[i]) for i=0..3|\n",
    "|20|_mm512_reduce_max_epi64|145|vshufi64x2 zmm2, zmm0, zmm0, 0xb1| ~ move part of zmm0 to zmm2|\n",
    "|20|_mm512_reduce_max_epi64|152|vpmaxsq zmm0, zmm0, zmm2|zmm0[i] = max(zmm0[i],zmm2[i]) for i=0..3|\n",
    "|20|_mm512_reduce_max_epi64|158|vpermq zmm2, zmm0, 0xb1|~ zmm2[0] = zmm0[1], zmm2[1] = zmm0[0], ...|\n",
    "|20|_mm512_reduce_max_epi64|165|vpmaxsq zmm0, zmm0, zmm2|zmm0[i] = max(zmm0[i],zmm2[i]) for i=0..3|\n",
    "\n",
    "Osservazioni:\n",
    "- la maggior parte delle istruzioni SIMD di questa funzione solo solo per _mm512_reduce_min_pd e _mm512_reduce_max_epi64, entrambe restutuiscono il valore minimo(massimo) di tipo double(long) del registro vettorizzato.\n",
    "- tutte le altre funzioni SIMD sono eseguite in una sola istruzione (set1 utilizza una istruzione per spostare il valore dalla memoria a un registro, la parte di estensione da registro a registro vettorizzato è una sola istruzione)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possibile miglioramento\n",
    "Ho scitto una funzione **isSortedAVX512_v1** ed ho provato sia a chiamarla all'inizio di ogni ciclo interno sia ad inserirla all'interno dell'esecuzione normale.\n",
    "Degli algoritmi considerati nessuno rende considerevolmente più ordinato l'array dopo ogni iterazione quindi mi aspetto che questa modifica non porti miglioramenti in nessun algoritmo.\n",
    "\n",
    "Comparando queste versioni con v5 si nota (come atteso) che sono considerevolmente più lente all'aumentare della lunghezza. Questo è dovuto al fatto che per ogni iterazione di `i` eseguo una lettura in più del resto dell'array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InsertionSort\n",
    "Ho implementato una versione dell'insertionSort e fatto generare una versione da Chat-GPT e una da microsoft copilot. Delle due IA solo la seconda sembra essere riuscia a produrre un codice con qualche utilità (non sempre funziona, ritengo di poterlo sistemare nei prossimi giorni)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void insertionSortAVX512_v1(double * v, int dim) {\n",
    "    for (int i = 1; i < dim; ++i) {\n",
    "        int j = i-1;\n",
    "        double key = v[i];\n",
    "        while(j >= 8 && v[j-8] > key) {\n",
    "            __m512d vec = _mm512_loadu_pd(&v[j-7]);\n",
    "            _mm512_storeu_pd(&v[j-6],vec);\n",
    "            j -= 8;\n",
    "        }\n",
    "        while (j >= 0 && v[j] > key) {\n",
    "            v[j + 1] = v[j];\n",
    "            j--;\n",
    "        }\n",
    "        v[j + 1] = key;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idea alla base è spostare 8 elementi alla volta se il valore corrente va spostato di almeno 8 elementi, altrimenti eseguo il classico ciclo senza istruzioni SIMD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Osservazioni\n",
    "Nè Chat-GPT nè Microsoft copilot sono state in grado di fornire una versione che funzionasse.\n",
    "Questo algoritmo utilizza solamente 2 istruzioni SIMD poichè non c'è altro da vettorizzare (il confronto è sufficiente con l'elemento di 8 pposizioni precedente).\n",
    "\n",
    "Constatiamo che questo algoritmo sia in partenza (nella versione senza istruzioni SIMD) più efficiente di SelectionSort per il fatto che per le iterazioni interne terminano appena trovato un valore minore del corrente.\n",
    "Notiamo che la versione SIMD di questo algoritmo sfrutta solamente la $\\textrm{load}^1$ e la $\\textrm{store}^1$ rispetto alle molteplici utilizzate dal SelectionSort, questo perchè non si ha bisogno di calcoli articolati, ma solo di spostare i valori nel caso la comparazione dia esito positivo.\n",
    "\n",
    "Eseguiamo il codice e $\\textrm{confrontiamolo}^2$ con i tempi di esecuione del selectionSort:\n",
    "\n",
    "|Dimensione|SelectionSort_v0|SelectionSort_v5|Miglioramento %|InsertionSort_v0|InsertionSort_v2|Miglioramento %| Miglioramento SelV5/InsV2|\n",
    "|-----|-----|-----|-----|-----|-----|-----|-----|\n",
    "| 1000 |276 | 127 |54 |111 |40 |64 |68|\n",
    "| 10000|15'399|5'287|66|8'973|2'860|68|46|\n",
    "| 100000|1'392'983|435'025|69|796'252|262'530|67|40|\n",
    "| 200000 $\\textrm{ }^3$|5'544'907|1'856'801|67|3'219'257|1'054'202|67|43|\n",
    "\n",
    "E' evidente la differenza\n",
    "\n",
    "\n",
    "\n",
    "Note:\n",
    "1. rispettivamente *_mm512_loadu_pd* per caricare i valori nei registri e *_mm512_storeu_pd* per spostare i valori in memoria\n",
    "2. utilizzando sempre la flag O1\n",
    "3. Purtroppo aumentare di un altro ordine di grandezza non è possibile perchè rende la dimensione troppo grande, quindi mi limito a raddoppiare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi compilato\n",
    "Come sottolineato precedentemente, il numero di istruzioni SIMD è nullo, quindi è possibile solo notare che il codice asm è una fedele trasposizione dal c++ in modo diretto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bubbleSort\n",
    "Analogamente al selectionSort ho implementato 2 versioni del bubbleSort più una in cui il ciclo interno è branchless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void bubbleSortAVX512_v1(double * v, int dim) {\n",
    "    __m512d arr;\n",
    "    for(int i = dim - 1 ; i >= 0 ; i--) {\n",
    "        double maximum;\n",
    "        int j = 0;\n",
    "        while(j < i - 8) {\n",
    "            arr = _mm512_loadu_pd(&v[j]);\n",
    "            maximum = _mm512_reduce_max_pd(arr);\n",
    "            if(maximum != v[j+7]) {\n",
    "                for(int k = 0 ; k < 8 ; k++) {\n",
    "                    if(v[j+k] == maximum) {\n",
    "                        std::swap(v[j+7],v[j+k]);\n",
    "                        break;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            j += 7;\n",
    "        }\n",
    "        while(j <= i - 1) {\n",
    "            if(v[j] > v[j+1]) {\n",
    "                std::swap(v[j],v[j+1]);\n",
    "            }\n",
    "            j++;\n",
    "        }\n",
    "    } \n",
    "    t.stop();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void bubbleSortAVX512_v2(double * v, int dim) {\n",
    "    __m512d arr,max_vect;\n",
    "    long idxs_arr[16] = {0,1,2,3,4,5,6,7};\n",
    "    __m512i c,idxs_vect = _mm512_loadu_epi64(idxs_arr);\n",
    "    __mmask8 mask;\n",
    "    for(int i = dim - 1 ; i >= 0 ; i--) {\n",
    "        double maximum;\n",
    "        int j = 0;\n",
    "        while(j < i - 8) {\n",
    "            arr = _mm512_loadu_pd(&v[j]);\n",
    "            maximum = _mm512_reduce_max_pd(arr);\n",
    "            if(maximum != v[j+7]) {\n",
    "                max_vect = _mm512_set1_pd(maximum);\n",
    "                mask = _mm512_cmpeq_pd_mask(arr,max_vect);\n",
    "                c = _mm512_maskz_abs_epi64(mask,idxs_vect);\n",
    "                int idx = j + _mm512_reduce_max_epi64(c);\n",
    "                std::swap(v[idx],v[j+7]);\n",
    "            }\n",
    "            j += 7;\n",
    "        }\n",
    "        while(j <= i - 1) {\n",
    "            if(v[j] > v[j+1]) {\n",
    "                std::swap(v[j],v[j+1]);\n",
    "            }\n",
    "            j++;\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void bubbleSortAVX512_v3(double * v, int dim) {\n",
    "    __m512d arr,max_vect;\n",
    "    long idxs_arr[16] = {0,1,2,3,4,5,6,7};\n",
    "    __m512i c,idxs_vect = _mm512_loadu_epi64(idxs_arr);\n",
    "    __mmask8 mask;\n",
    "    for(int i = dim - 1 ; i >= 0 ; i--) {\n",
    "        double maximum;\n",
    "        int j = 0;\n",
    "        while(j < i - 8) {\n",
    "            arr = _mm512_loadu_pd(&v[j]);\n",
    "            maximum = _mm512_reduce_max_pd(arr);\n",
    "            max_vect = _mm512_set1_pd(maximum);\n",
    "            mask = _mm512_cmpeq_pd_mask(arr,max_vect);\n",
    "            c = _mm512_maskz_abs_epi64(mask,idxs_vect);\n",
    "            int idx = j + _mm512_reduce_max_epi64(c);\n",
    "            std::swap(v[idx],v[j+7]);\n",
    "            j += 7;\n",
    "        }\n",
    "        while(j <= i - 1) {\n",
    "            if(v[j] > v[j+1]) {\n",
    "                std::swap(v[j],v[j+1]);\n",
    "            }\n",
    "            j++;\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho deciso di implementare il bubbleSort invertendo l'elemento di valore (tra gli 8 confrontati) maggiore con quello nel registro con indice più alto in ogni passata del ciclo interno.\n",
    "Analogamente al selectionSort ho scritto una prima versione che utilizza un ciclo for e una che utilizza le istruzioni SIMD per trovare l'indice del valore massimo.\n",
    "Ho scritto anche una terza versione che sposta a priori il massimo all'indice massimo del vettore, il ciclo interno è branchless ma sicuramente risulterà più lento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Osservazioni\n",
    "- Anche qui nè Chat-GPT nè Microsoft copilot sono state in grado di restituire del codice utile. \n",
    "- Il codice risultante è estremamente simile a quello del selectionSort\n",
    "\n",
    "Tabella dei tempi (presi con flag O1 e array di numeri generati casualmente)\n",
    "|Dimensione|v0|v1|v2|Peggioramento v0/v1|Peggioramento v0/v2|Peggioramento v1/v2|\n",
    "|--|--|--|--|--|--|--|\n",
    "|1000|454|491|662|-8.15%|-37.0%|-26.68%|\n",
    "|10000|33'433|42'219|56'759|-26.28%|-69.77%|-34.44%|\n",
    "|100000|4'020'427|4'122'256|5'559'596|-2.53%|-38.28%|-34.87%|\n",
    "\n",
    "Come si evince dalla tabella più andiamo ad utilizzare istruzioni SIMD più l'lagoritmo è lento. Misurando le differenze di tempo all'interno dell'if tra v1 e v2 vediamo che v2 ha un ciclo interno più rapido di v1. Leggendo il codice c++ notiamo anche che quella è l'unica parte in cui le due versioni differiscono. Questo significa che deve esserci una differenza nel compilato tra le due versioni (oltre all'ovvia differenza tra le parti di codice diverse anche tra le parti di codice uguali).\n",
    "\n",
    "Ho confrontato anche cambiando i livelli di ottimizzazione (O0,O1,O2 ed O3) e questa caratteristica rimane costante, analizziamo dunque i due compilati (con flag O1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubbleSortAVX512_v1(double*, int):\n",
    "        mov     r9d, esi\t\t\t\t|\n",
    "        mov     r8d, esi\t\t\t\t|\n",
    "        dec     r8d\t\t\t\t\t|-> inizio funzione\n",
    "        js      .L11\t\t\t\t\t|\n",
    "        sub     r9d, 9\t\t\t\t|\n",
    "        jmp     .L13\t\t\t\t\t|\n",
    ".L36:\n",
    "        vmovsd  QWORD PTR [r10], xmm1\n",
    "        vmovsd  QWORD PTR [rdx], xmm2\n",
    ".L14:\n",
    "        add     eax, 7\n",
    "        add     rcx, 56\n",
    "        cmp     eax, r9d\n",
    "        jge     .L35\n",
    ".L19:\n",
    "        mov     r10, rcx\n",
    "        vmovupd zmm0, ZMMWORD PTR [rcx-56]\t\t|\n",
    "        vextractf64x4   ymm1, zmm0, 0x1\t\t\t|\n",
    "        vmaxpd  ymm1, ymm1, ymm0\t\t\t|\n",
    "        vextractf64x2   xmm0, ymm1, 0x1\t\t\t|\n",
    "        vmaxpd  xmm0, xmm0, xmm1\t\t\t|-> loadu + reduce_max\n",
    "        vpermilpd       xmm1, xmm0, 1\t\t\t|\n",
    "        vmaxpd  xmm0, xmm0, xmm1\t\t\t|\n",
    "        vmovsd  xmm2, QWORD PTR [rcx]\t\t\t|\n",
    "        vucomisd        xmm2, xmm0\t        \t|\n",
    "        jp      .L28\t\t                        |\n",
    "        je      .L14\t\t\t|-> continuo il for interno\n",
    ".L28:\n",
    "        mov     rdx, rcx\t\t\t\t\t|\n",
    "        lea     rsi, [rcx-64]\t\t\t\t\t|\n",
    ".L18:\n",
    "        vmovsd  xmm1, QWORD PTR [rdx]\t        \t\t|\n",
    "        vucomisd        xmm1, xmm0\t\t\t\t|\n",
    "        jp      .L16\t\t|-> \n",
    "        je      .L36\t\t\t|-> continuo il for interno\n",
    ".L16:\n",
    "        sub     rdx, 8\t        |\n",
    "        cmp     rdx, rsi\t|\n",
    "        jne     .L18\t\t|-> ciclo for per trovare il massimo degli 8\n",
    "        jmp     .L14\t\t\t|-> continuo il for interno\n",
    ".L35:\n",
    "        cmp     eax, r8d\n",
    "        jge     .L20\t\t\t|-> parte finale ciclo for esterno\n",
    ".L26:\n",
    "        cdqe\n",
    "        jmp     .L23\n",
    ".L21:\n",
    "        inc     rax\n",
    "        cmp     r8d, eax\n",
    "        jle     .L20\n",
    ".L23:\n",
    "        vmovsd  xmm0, QWORD PTR [rdi+rax*8]\t\t|\n",
    "        vmovsd  xmm1, QWORD PTR [rdi+8+rax*8]\t\t|\n",
    "        vcomisd xmm0, xmm1\t\t\t\t|\n",
    "        jbe     .L21\t\t\t\t        |-> ciclo while SISD\n",
    "        vmovsd  QWORD PTR [rdi+rax*8], xmm1\t\t|\n",
    "        vmovsd  QWORD PTR [rdi+8+rax*8], xmm0\t\t|\n",
    "        jmp     .L21\n",
    ".L37:\n",
    "        ret\n",
    ".L20:\n",
    "        dec     r8d\t\t\t\t\t|\n",
    "        dec     r9d\t\t\t\t\t|\n",
    ".L13:\t\t\t\t\t\t        |-> parte finale del ciclo for esterno\n",
    "        lea     rcx, [rdi+56]\t\t                |\n",
    "        mov     eax, 0\t\t\t        \t|\n",
    "        cmp     r8d, 8\t\t\t\t        |\n",
    "        jg      .L19\t\t\t                |-> torno alla parte della funzione giusta in base alla lunghezza rimasta\n",
    "        test    r8d, r8d\t\t\t\t|\n",
    "        jle     .L37\t\t\t\t\t|\n",
    "        mov     eax, 0\t\t\t        \t|\n",
    "        jmp     .L26\t\t\t\t\t|\n",
    ".L11:\n",
    "        ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubbleSortAVX512_v2(double*, int):\n",
    "        mov     r9d, esi\t\t\t\t\t\t\t\t\t\t|\n",
    "        mov     r8d, esi\t\t\t\t\t\t\t\t\t\t|\n",
    "        dec     r8d\t\t\t\t\t\t\t\t\t\t\t|\n",
    "        js      .L38\t\t\t\t\t\t\t\t\t\t\t|-> inizio funzione\n",
    "        sub     r9d, 9\t\t\t\t\t\t\t\t\t\t        |\n",
    "        vmovdqa64       zmm3, ZMMWORD PTR .LC0[rip]\t\t\t                                |\n",
    "        jmp     .L40\t\t\t\t\t\t\t\t\t\t\t|\n",
    ".L52:\n",
    "        vbroadcastsd    zmm0, xmm0\t\t\t\t\t\t\t|\n",
    "        vcmppd  k1, zmm2, zmm0, 0\t\t\t\t\t\t\t|\n",
    "        vpabsq  zmm0{k1}{z}, zmm3\t\t\t\t\t\t\t|\n",
    "        vshufi64x2      zmm2, zmm0, zmm0, 78\t\t\t\t        \t|\n",
    "        vpmaxsq zmm0, zmm0, zmm2\t\t\t\t\t\t\t|\n",
    "        vshufi64x2      zmm2, zmm0, zmm0, 177\t\t\t                \t|\n",
    "        vpmaxsq zmm0, zmm0, zmm2\t\t\t\t\t\t\t|-> set1+cmpeq+mask+reduce_max\n",
    "        vpermq  zmm2, zmm0, 177\t\t\t\t\t\t\t\t|\n",
    "        vpmaxsq zmm0, zmm0, zmm2\t\t\t\t\t\t\t|\n",
    "        vmovq   rax, xmm0\t\t\t\t\t\t\t\t|\n",
    "        add     eax, edx\t\t\t\t\t\t\t\t|\n",
    "        cdqe\t\t\t\t\t\t\t\t\t\t|\n",
    "        lea     rax, [rdi+rax*8]\t\t\t\t\t\t\t|\n",
    "        vmovsd  xmm0, QWORD PTR [rax]\t\t\t\t\t\t        |\n",
    "        vmovsd  QWORD PTR [rax], xmm1   \t\t\t\t\t\t|\n",
    "        vmovsd  QWORD PTR [rsi], xmm0\t        \t\t\t\t\t|\n",
    ".L41:\n",
    "        add     edx, 7\t\t\t        |\n",
    "        add     rcx, 56\t\t\t        |\n",
    "        cmp     edx, r9d\t\t\t|-> gestione while SIMD\n",
    "        jge     .L57\t\t\t\t|\n",
    ".L43:\n",
    "        mov     rsi, rcx\t\t\t        \t|\n",
    "        vmovupd zmm2, ZMMWORD PTR [rcx-56]\t\t\t|\n",
    "        vextractf64x4   ymm1, zmm2, 0x1\t\t\t\t|\n",
    "        vmaxpd  ymm1, ymm1, ymm2\t\t\t\t|\n",
    "        vextractf64x2   xmm0, ymm1, 0x1\t\t\t\t|\n",
    "        vmaxpd  xmm0, xmm0, xmm1\t\t\t\t|-> loadu + reduce_max\n",
    "        vpermilpd       xmm1, xmm0, 1\t\t\t\t|\n",
    "        vmaxpd  xmm0, xmm0, xmm1\t\t\t\t|\n",
    "        vmovsd  xmm1, QWORD PTR [rcx]\t\t\t\t|\n",
    "        vucomisd        xmm1, xmm0\t\t\t        |\n",
    "        jp      .L52\t\t\t\t\t\t|\n",
    "        je      .L41\t\t\t\t\t\t|\n",
    "        jmp     .L52\t\t\t\t\t\t|\n",
    ".L57:\n",
    "        cmp     edx, r8d\t\t\t|\n",
    "        jge     .L44\t\t\t\t|-> gestion while SISD\n",
    ".L50:\n",
    "        movsx   rax, edx\n",
    "        jmp     .L47\n",
    ".L45:\n",
    "        inc     rax\n",
    "        cmp     r8d, eax\n",
    "        jle     .L44\n",
    ".L47:\n",
    "        vmovsd  xmm0, QWORD PTR [rdi+rax*8]\t\t                |\n",
    "        vmovsd  xmm1, QWORD PTR [rdi+8+rax*8]\t                        |\n",
    "        vcomisd xmm0, xmm1\t\t\t\t\t\t|\n",
    "        jbe     .L45\t\t\t\t\t\t\t|-> while SISD\n",
    "        vmovsd  QWORD PTR [rdi+rax*8], xmm1\t\t                |\n",
    "        vmovsd  QWORD PTR [rdi+8+rax*8], xmm0\t                        |\n",
    "        jmp     .L45\n",
    ".L58:\n",
    "        ret\n",
    ".L44:\n",
    "        dec     r8d\n",
    "        dec     r9d\n",
    ".L40:\n",
    "        lea     rcx, [rdi+56]\t\t                |\n",
    "        mov     edx, 0\t\t\t\t        |\n",
    "        cmp     r8d, 8\t\t\t\t        |\n",
    "        jg      .L43\t\t\t\t\t|\n",
    "        test    r8d, r8d\t\t\t\t|-> gestione for interno\n",
    "        jle     .L58\t\t\t\t\t|\n",
    "        mov     edx, 0\t\t\t\t        |\n",
    "        jmp     .L50\t\t\t\t\t|\n",
    ".L38:\n",
    "        ret\n",
    ".LC0:\n",
    "        .quad   0\t\t|\n",
    "        .quad   1\t\t|\n",
    "        .quad   2\t\t|\n",
    "        .quad   3\t\t|\n",
    "        .quad   4\t\t|-> numeri in memoria per gli indici dei registri zmm\n",
    "        .quad   5\t\t|\n",
    "        .quad   6\t\t|\n",
    "        .quad   7\t\t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le differenze tra i due compilati non sembrano spiegare come la versione che utilizza più istruzioni SIMD sia più lenta dell'altra.\n",
    "\n",
    "Considerando che durante l'esecuzione del bubbleSort la parte non ordinata viene parzialmente ordinata ma la versione 1 di questo algoritmo cicla fino a trovare il massimo il numero di volte che viene eseguito il for (con variabile k) è decisamente maggiore della media (~4.4 per gli array di 100 e ~7.6 con quelli di 1000 elementi). Quindi non è la parte interna all' `if(maximum != v[j+7]) {` a renderlo più veloce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partiamo dal fatto che la `reduce_max` è la parte più onerosa della funzione, per ridurne l'utilizzo possiamo confrontare il vettore corrente con il numero maggiore trovato nell'ultiumo ciclo. Sarà molto probabile che il massimo precedente sia maggiore di tutti i valori del vettore corrente quindi gestire questo caso senza `reduce_max` contribuisce molto al miglioramento. Possiamo anche controllare se il valore all'indice massimo è il massimo corrente, nel qual caso non necessiteremo della funzione `swap`.\n",
    "\n",
    "Questo ultimo caso risulterà molto più frequente rispetto al trovare il massimo del vettore corrente in qualsiasi altra posizione, poichè i vettori sono sempre tutti allineati tra loro ed il massimo corrente viene spostato all'indice corrente maggiore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void bubbleSortAVX512_v6(double * v, int dim) {\n",
    "    __m512d arr, curr;\n",
    "    __mmask8 mask;\n",
    "    for(int i = dim - 1 ; i >= 0 ; i--) {\n",
    "        int j = 1;\n",
    "        curr =  _mm512_set1_pd(v[0]);\n",
    "        while(j < i - 8) {\n",
    "            arr = _mm512_loadu_pd(&v[j]);\n",
    "            mask = _mm512_cmplt_pd_mask(curr,arr);\n",
    "            if(!mask) {\n",
    "                std::swap(v[j+7],v[j-1]);\n",
    "            } else {\n",
    "                curr = _mm512_set1_pd(v[j+7]);\n",
    "                mask = _mm512_cmplt_pd_mask(curr,arr);\n",
    "                if(mask) {\n",
    "                    double maximum = _mm512_reduce_max_pd(arr);\n",
    "                    curr = _mm512_set1_pd(maximum);\n",
    "                    mask = _mm512_cmpeq_pd_mask(arr,curr);\n",
    "                    int idx = _tzcnt_u32(mask) + j;\n",
    "                    std::swap(v[j+7],v[idx]);\n",
    "                }\n",
    "            }\n",
    "            j+=8;\n",
    "        }\n",
    "        while(j <= i ) {\n",
    "            if(v[j-1] > v[j]) {\n",
    "                std::swap(v[j-1],v[j]);\n",
    "            }\n",
    "            j++;\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa versione ci dà un miglioramento che va dal 60% con array di dimensione 1000 all'80% con array di dimensione 100000. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O1 vs O2 vs O3\n",
    "\n",
    "O3 non garantisce l'equivalenza a O2 e O1, ma è il più veloce.\n",
    "O2 dovrebbe essere il più veloce ma (almeno) con selectionSort v8 (nella tesi v3) è più lento (del 26%) di O1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qsort Intel\n",
    "- per compilare utilizza O3\n",
    "- ordine di esecuzione delle funzioni:\n",
    "    1. qsort                (x86simdsort-static-incl.h)\n",
    "    2. _qsort               (xss-common-qsort.h)\n",
    "    3. xss_qsort            (xss-common-qsort.h)\n",
    "    4. qsort_               (xss-common-qsort.h)\n",
    "    5. sort_n               (xss-network-qsort.hpp)\n",
    "    5. sort_n_vec           (xss-network-qsort.hpp)\n",
    "    6. sort_vectors         (xss-network-qsort.hpp)\n",
    "    7. bitonic_sort_n_vec   (xss-network-qsort.hpp)\n",
    "    8. optimal_sort_4       (xss-optimal-networks.hpp)\n",
    "    9. COEX                 (xss-common-qsort)\n",
    "    10. merge_n_vec         (xss-network-qsort.hpp)\n",
    "    11. get_pivot_smart     (xss-pivot-selection.hpp)\n",
    "    12. get_pivot           (xss-pivot-selection.hpp)\n",
    "    13. sort_vec            (avx512-64bit-common.h)\n",
    "    14. sort_zmm_64bit      (avx512-64bit-common.h)\n",
    "    15. partition_unrolled  (xss-common-qsort.h)\n",
    "    16. partition           (xss-common-qsort.h)\n",
    "\n",
    "- struttura algoritmo qsort_:\n",
    "    1. se ha terminato il numero di iterazioni esegue la std::sort()\n",
    "    2. se la dimensione rimanente è minore di vtype::network_sort_threshold esegue la sort_n (bitonic networks)\n",
    "    3. esegue la get_pivot_smart\n",
    "    4. se la get_pivot_smart dice che è ordinato, ritorno\n",
    "    5. eseguo la partition_unrolled\n",
    "    6. eseguo nuovamente la qsort_ per dx e sx se da quel lato la dim è > 0\n",
    "\n",
    "- struttura algoritmo get_pivot_smart:\n",
    "    1. se la dimensione è minore di 4*numVecs*numlanes usa la get_pivot\n",
    "    2. prendi un tot di campioni (8 valori contigui) dell'array\n",
    "    3. ordina i campioni (con sort_vectors)\n",
    "    4. se smallest==largest restituisce get_pivot_near_constant(arr)\n",
    "    5. se mediana,smallest e largest sono tutte diverse tra loro restituisce la mediana\n",
    "    6. se median==smallest restituisce choosePivotMedianIsSmallest\n",
    "    7. se median==largest restituisce choosePivotMedianIsLargest\n",
    "\n",
    "- struttura algoritmo get_pivot:\n",
    "    1. prende vtype::numlanes valori casuali dell'array\n",
    "    2. li ordina (con sort_vec)\n",
    "    3. restituisce la mediana\n",
    "\n",
    "- struttura sort_vec:\n",
    "    1. chiama la sort_zmm_64bit\n",
    "\n",
    "- struttura sort_zmm_64bit:\n",
    "    Una strana serie di cmp_merge fino a restituire il registro ordinato\n",
    "\n",
    "- struttura sort_vectors :\n",
    "    1. bitonic_sort_n_vec\n",
    "    2. merge_n_vec\n",
    "\n",
    "- struttura merge_n_vec:\n",
    "    1. se numero vettori \"finito\" termino\n",
    "    2. merge_step_n_vec\n",
    "    3. merge_n_vec(numPer*2)\n",
    "\n",
    "- struttura merge_step_n_vec:\n",
    "    1. merge_substep_n_vec (Do cross vector merges)\n",
    "    2. internal_merge_n_vec (Do internal vector merges)\n",
    "\n",
    "- struttura merge_substep_n_vec:\n",
    "    1. Reverse upper half of vectors (using reverse_n)\n",
    "    2. Do compare exchanges (using COEX)\n",
    "    3. merge_substep_n_vec(prima metà dei registri)\n",
    "    4. merge_substep_n_vec(seconda metà dei registri)\n",
    "\n",
    "- struttura internal_merge_n_vec:\n",
    "    1. se prima chiamata reverse then merge (using reverse_n, COEX, merge_n)\n",
    "    2. se seconda chiamata swap then merge (using swap_n,COEX, merge_n)\n",
    "    3. richiamo internal_merge_n_vec\n",
    "\n",
    "- struttura bitonic_sort_n_vec:\n",
    "    attraverso algoritmo di bitonic network ordina i primi valori degli array, i secondi, ...\n",
    "\n",
    "- struttura partition_unrolled:\n",
    "    1. se num_unrolls == 0 o rimensione < 3*num_unroll * vtype::numlanes esegue la partition\n",
    "    2. ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deepseek-r1:14b\n",
    ">>> can you write a little c function that uses intel's avx-512 intrinsics to speed up the execution?\n",
    "<think>\n",
    "Okay, so I need to write a C function using Intel's AVX-512 intrinsics to speed things up. Hmm, where do I start? I remember that AVX-512 is an instruction set \n",
    "extension for SIMD operations, allowing for wider vectors than previous versions. It can handle 512 bits, so that's good for processing more data in parallel.\n",
    "\n",
    "I think the first step is to include the necessary headers. From what I've read before, I should include <immintrin.h> which includes all the AVX-512 functions and \n",
    "constants. But wait, do I need any other headers? Maybe <x86intrin.h>? Or perhaps it's better to just use <immintrin.h>.\n",
    "\n",
    "Next, I need to declare a vector type. Oh right, __m512 is the type for 512-bit vectors in AVX-512. So I'll declare two variables of this type, say 'a' and 'b'. \n",
    "How do I initialize them? Using _mm512_set_1pii() for scalar values repeated across all elements. But wait, that function isn't available in the latest versions. \n",
    "Oh right, maybe it's better to use _mm512_set1_epi32() or something like that.\n",
    "\n",
    "Wait, I'm getting a bit confused about the functions. Let me think: _mm512_set_1p_i32() doesn't exist \n",
    "anymore. The correct function is _mm512_set1_epi32(), which sets all elements of the vector to a single \n",
    "scalar value. So for example, __m512i a = _mm512_set1_epi32(5); would set each element in 'a' to 5.\n",
    "\n",
    "Then, I need to perform some operations on these vectors. Maybe add them together? The function for \n",
    "addition is _mm512_add_epi32(). So I can do something like __m512i result = _mm512_add_epi32(a, b); that \n",
    "should add corresponding elements of 'a' and 'b'.\n",
    "\n",
    "But wait, what if I want to multiply them? Oh right, there's _mm512_mullo_epi32(), which multiplies each \n",
    "pair of integers and stores the lower 32 bits. But I'm not sure about overflow; maybe that's handled \n",
    "automatically.\n",
    "\n",
    "After performing operations, how do I convert the result back to a scalar if needed? There's \n",
    "_mm512_reduce_add_epi32() which sums all elements into a single integer. So if I have 'result', I can get \n",
    "the sum with int sum = _mm512_reduce_add_epi32(result);.\n",
    "\n",
    "Putting it all together, the function might look something like this:\n",
    "\n",
    "#include <immintrin.h>\n",
    "\n",
    "int add_vectors(int *a_vec, int *b_vec) {\n",
    "    __m512i a = _mm512_loadu_si512((const int64_t *)a_vec);\n",
    "    __m512i b = _mm512_loadu_si512((const int64_t *)b_vec);\n",
    "    __m512i result = _mm512_add_epi32(a, b);\n",
    "    return _mm512_reduce_add_epi32(result);\n",
    "}\n",
    "\n",
    "Wait, but _mm512_loadu_si512 takes a pointer to int64_t? Or is it 8 integers since each vector is 512 bits \n",
    "(which is 8 * 64 bits). So if I'm dealing with 32-bit integers, maybe I should use _mm512_loadu_epi32(). \n",
    "Hmm, not sure about the pointer casting.\n",
    "\n",
    "Alternatively, perhaps I can just load from an int pointer by casting it to __m512i. Maybe using \n",
    "_mm512_setr_epi32() if I have specific elements, but in this case, since I'm loading from arrays, it's \n",
    "better to use load functions.\n",
    "\n",
    "Wait, another approach: if I have two arrays of integers, each 8 elements long (since 512 bits / 64 bits \n",
    "per element = 8 doubles or 16 integers), depending on the data type. So for 32-bit integers, each vector \n",
    "can hold 16 integers (512 / 32). So if I have a_vec and b_vec as arrays of at least 16 integers each, I \n",
    "can load them into vectors.\n",
    "\n",
    "But in my initial example, the function takes single int pointers. Wait, maybe I should adjust the \n",
    "parameters to be __m512i instead? Or perhaps it's better to pass the vectors as parameters and then \n",
    "perform operations on them.\n",
    "\n",
    "Wait no, the user asked for a function that uses AVX-512 intrinsics. So perhaps the function will take two \n",
    "arrays (pointers) and return the result of some operation, like adding corresponding elements.\n",
    "\n",
    "But in my initial example, I think I made a mistake with the loading functions. Let me correct that. For \n",
    "32-bit integers, the load function should be _mm512_loadu_epi32(), but wait, does that exist? Or is it \n",
    "_mm512_loadu_si512() for any type?\n",
    "\n",
    "I think I need to use the right intrinsic for loading. Since __m512i can hold integers of various types, \n",
    "perhaps using _mm512_loadu_si512 with a cast to int pointer would load 8 doublewords (64 bits each), which \n",
    "is 8 * 8 = 64 bytes total. But I'm dealing with 32-bit integers, so that might not be the right approach.\n",
    "\n",
    "Wait, perhaps I should use _mm512_loadu_epi32(), but I'm not sure if that's a valid function. Maybe it's \n",
    "better to check the correct way to load 32-bit integers into __m512i vectors.\n",
    "\n",
    "Alternatively,^[[A^[[B sin each __m512i can hold 16 int32_t elements (since 512 bits / 32 bits = 16), I can use \n",
    "_mm512_set_epi32() to create the vector from individual integers. But that's tedious if I have an array.\n",
    "\n",
    "Wait, maybe using _mm512_loadu_si512 with a cast to int pointer is okay because it will load 8 doublewords \n",
    "(64 bits) which can be interpreted as 16 32-bit integers, but I'm not sure. Alternatively, perhaps the \n",
    "code should be:\n",
    "\n",
    "__m512i a = _mm512_loadu_si512(a_vec);\n",
    "__m512i b = _mm512_loadu_si512(b_vec);\n",
    "\n",
    "But then, if a_vec and b_vec are arrays of int32_t, this might not be the correct way. Maybe I should use \n",
    "_mm512_maskload_epi32() or something else.\n",
    "\n",
    "Alternatively, perhaps it's better to write code that operates on 8 elements at once, using __m512d for \n",
    "double-precision floating points. For example, adding two vectors of doubles:\n",
    "\n",
    "#include <immintrin.h>\n",
    "\n",
    "void add_vectors(double *a, double *b, double *result) {\n",
    "    __m512d a_vec = _mm512_loadu_pd(a);\n",
    "    __m512d b_vec = _mm512_loadu_pd(b);\n",
    "    __m512d sum = _mm512_add_pd(a_vec, b_vec);\n",
    "    _mm512_storeu_pd(result, sum);\n",
    "}\n",
    "\n",
    "This function adds two vectors of doubles and stores the result in another vector. It's more efficient \n",
    "than scalar operations because it uses SIMD to add all elements at once.\n",
    "\n",
    "But the original question was about a C function using AVX-512 intrinsics for speed. So perhaps the user \n",
    "is looking for something like this, but maybe for integers instead of doubles.\n",
    "\n",
    "Alternatively, if I'm working with integers, perhaps using __m512i and performing add operations:\n",
    "\n",
    "#include <immintrin.h>\n",
    "\n",
    "void add_int_vectors(int *a, int *b, int *result) {\n",
    "    __m512i a_vec = _mm512_loadu_si512(a);\n",
    "    __m512i b_vec = _mm512_loadu_si512(b);\n",
    "    __m512i sum = _mm512_add_epi32(a_vec, b_vec);\n",
    "    _mm512_storeu_si512(result, sum);\n",
    "}\n",
    "\n",
    "But wait, this would require that a and b are arrays of 16 integers each (since 512 bits / 32 bits per int \n",
    "= 16). So the function adds corresponding elements in a and b and stores the result in result.\n",
    "\n",
    "However, I'm not sure if _mm512_add_epi32 is the correct intrinsic for adding 32-bit integers. Maybe it's \n",
    "_mm512_i32_add() or something else. Let me check: no, _mm512_add_epi32 is indeed the correct function to \n",
    "add each element of two __m512i vectors.\n",
    "\n",
    "But perhaps a more complete example would include multiple steps, like loading, performing operations, and \n",
    "storing back.\n",
    "\n",
    "Another consideration is whether to use _mm512_mask... functions if I need to control which elements are \n",
    "operated on. But2 for simplicity, maybe starting with basic operations is better.\n",
    "\n",
    "Also, it's important to ensure that the compiler doesn't optimize away the vector operations, so using \n",
    "appropriate alignment and perhaps compiler flags like -mavx512f would be necessary.\n",
    "\n",
    "In summary, the thought process was about determining what kind of function the user wants (vector \n",
    "addition, scalar multiplication, etc.), choosing between integer or floating-point types, selecting the \n",
    "correct intrinsics for loading, adding, and storing, ensuring that the arrays are properly aligned, and \n",
    "considering any potential issues with compiler optimizations.\n",
    "</think>\n",
    "\n",
    "Here's a step-by-step explanation of how to create a function using AVX-512 intrinsics in C to add two \n",
    "vectors of integers:\n",
    "\n",
    "### Step 1: Include Necessary Headers\n",
    "First, include the header file for the Intel Intrinsics Guide, which provides the necessary functions and \n",
    "definitions.\n",
    "\n",
    "```c\n",
    "#include <immintrin.h>\n",
    "```\n",
    "\n",
    "### Step 2: Define the Function\n",
    "Define a function that takes three pointers to `int` arrays. The first two are input arrays, and the third \n",
    "is where the result will be stored.\n",
    "\n",
    "```c\n",
    "void add_int_vectors(int *a, int *b, int *result) {\n",
    "    // Function body goes here\n",
    "}\n",
    "```\n",
    "\n",
    "### Step 3: Load Vectors into SIMD Registers\n",
    "Use `_mm512_loadu_si512` to load each array into a 512-bit vector. This function loads the data in an \n",
    "unaligned manner, which is fine if the arrays are not aligned.\n",
    "\n",
    "```c\n",
    "__m512i a_vec = _mm512_loadu_si512(a);\n",
    "__m512i b_vec = _mm512_loadu_si512(b);\n",
    "```\n",
    "\n",
    "### Step 4: Perform Vector Addition\n",
    "Use `_mm512_add_epi32` to add the corresponding elements of `a_vec` and `b_vec`. This function performs \n",
    "element-wise addition on two `__m512i` vectors.\n",
    "\n",
    "```c\n",
    "__m512i sum = _mm512_add_epi32(a_vec, b_vec);\n",
    "```\n",
    "\n",
    "### Step 5: Store the Result Back into Memory\n",
    "Use `_mm512_storeu_si512` to store the resulting vector back into the `result` array. This function stores \n",
    "the data in an unaligned manner.\n",
    "\n",
    "```c\n",
    "_mm512_storeu_si512(result, sum);\n",
    "```\n",
    "\n",
    "### Step 6: Complete Function Definition\n",
    "Combine all these steps within the function body.\n",
    "\n",
    "```c\n",
    "void add_int_vectors(int *a, int *b, int *result) {\n",
    "    __m512i a_vec = _mm5124_loadu_si512(a);\n",
    "    __m512i b_vec = _mm512_loadu_si512(b);\n",
    "    __m512i sum = _mm512_add_epi32(a_vec, b_vec);\n",
    "    _mm512_storeu_si512(result, sum);\n",
    "}\n",
    "```\n",
    "\n",
    "### Step 7: Considerations\n",
    "- **Alignment**: If your arrays are aligned (e.g., on 64-byte boundaries), consider using \n",
    "`_mm512_loadl_epi64` or other aligned load functions for better performance.\n",
    "- **Compiler Flags**: Ensure that the compiler supports AVX-512 and that it is enabled. Use flags like \n",
    "`-mavx512f -O3` when compiling.\n",
    "- **Platform Compatibility**: Make sure your target platform supports AVX-512 instructions, as not all \n",
    "CPUs have this feature.\n",
    "\n",
    "This function efficiently adds two vectors of integers using AVX-512 SIMD intrinsics, performing the \n",
    "operation much faster than scalar code by leveraging parallel processing capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepseek-r1:14b\n",
    "- Question: you're a skilled Inel's c programmer, you have to write a fast executing version of the algorithm selectionSort that uses avx512f intrinsics to reduce the time of the esecution, the input is an array (pointer) of double and its size\n",
    "\n",
    "\n",
    "## think\n",
    "Okay, so I need to rewrite the selection sort algorithm using AVX512F intrinsics to make it \n",
    "faster. Hmm, where do I start? Well, selection sort works by finding the minimum element in a \n",
    "part of the array and placing it at the beginning, then repeating for the next position. But \n",
    "with AVX, maybe I can process multiple elements at once.\n",
    "\n",
    "First, I should think about how to load multiple doubles into vectors using AVX512. Each \n",
    "vector can hold 8 doubles since each double is 64 bits, and AVX512 has 64-bit vectors. So, I \n",
    "can load a block of 8 elements at a time.\n",
    "\n",
    "Wait, but selection sort compares elements one by one. How do I translate those comparisons \n",
    "into vector operations? Maybe for each group of 8 elements, I can find the index of the \n",
    "smallest one and then place it in the correct position.\n",
    "\n",
    "I remember that AVX512 has gather instructions which can load data from different indices into \n",
    "a single vector. That could be useful for comparing multiple elements without needing to loop \n",
    "through them with scalar operations.\n",
    "\n",
    "So, maybe the steps are: for each block of 8 elements starting at i, I'll create a vector that \n",
    "holds all these elements. Then, find the index of the minimum element within this vector. Once \n",
    "I have that index, I need to swap it into position if necessary.\n",
    "\n",
    "But wait, how do I handle the swapping? Swapping in vectors is possible with shuffles, but \n",
    "then I also need to update the actual array. Maybe after determining the min index, I can \n",
    "extract the value and place it where it needs to go using vector stores.\n",
    "\n",
    "I should also think about unrolling the loop as much as possible since AVX512 can handle 8 \n",
    "elements at a time. So, maybe process 8 elements per iteration, reducing the number of loops \n",
    "needed.\n",
    "\n",
    "Another thing: alignment. The array might not be aligned on a 64-byte boundary, so I need to \n",
    "handle that carefully when loading and storing vectors. Perhaps using _mm512_loadu_pd for \n",
    "loads and _mm512_storeu_pd for stores would help with unaligned access.\n",
    "\n",
    "Wait, but the selection sort has dependencies between iterations—each step selects the next \n",
    "minimum. So if I process 8 elements at a time, how do I handle the case where the min is \n",
    "outside the current block? That might complicate things because each block's processing \n",
    "affects subsequent blocks.\n",
    "\n",
    "Hmm, maybe for simplicity, first implement the AVX512 version for finding the min within a \n",
    "single vector and then move it to its place in the array. But this would still require scalar \n",
    "operations for moving elements around, which might negate some of the performance gains.\n",
    "\n",
    "Alternatively, perhaps I can process the array in chunks where each chunk is aligned, but that \n",
    "might not be efficient if the array isn't naturally aligned.\n",
    "\n",
    "I should also consider cache utilization. AVX512 benefits from good memory access patterns, so \n",
    "ensuring that data is loaded into the vector quickly and sequentially could help performance.\n",
    "\n",
    "Wait, maybe I can create a helper function that finds the index of the minimum in a set of 8 \n",
    "elements using vector operations. Then, for each group of 8 starting at i, find the min, swap \n",
    "it with i+min_index, and proceed.\n",
    "\n",
    "But to implement this, I'll need to:\n",
    "\n",
    "1. Load vectors from the array starting at different indices.\n",
    "2. Use vector comparisons to find the minimum index within each vector.\n",
    "3. Update the original array by swapping the elements, possibly using vector stores or scalar \n",
    "moves.\n",
    "\n",
    "I think the key is to use vector operations for as much as possible, especially the comparison \n",
    "and min finding part, which can be time-consuming in scalar loops.\n",
    "\n",
    "Another thought: Since selection sort has O(n^2) complexity, even with AVX optimization, it \n",
    "might not be the fastest sorting algorithm. Maybe I should consider if another algorithm like \n",
    "quicksort or heapsort would be more efficient, but the user specifically asked for selection \n",
    "sort.\n",
    "\n",
    "Alright, so focusing back on selection sort with AVX512:\n",
    "\n",
    "- For each i from 0 to n-8 (in steps of 8?), load a vector of 8^[OS elements starting at i.\n",
    "- Compare all 8 elements to find the index of the smallest one within that vector.\n",
    "- Then, determine if this min is larger than any in the previously sorted portion. If so, swap \n",
    "it into place.\n",
    "- Repeat for each subsequent block.\n",
    "\n",
    "Wait, but selection sort's inner loop selects the next minimum from the unsorted part and \n",
    "places it in the correct position. So if I process 8 elements at a time, I have to make sure \n",
    "that within those 8, the smallest is found and then compared against the previous sorted \n",
    "elements.\n",
    "\n",
    "Alternatively, perhaps it's better to process each element individually but vectorize the \n",
    "comparison steps as much as possible.\n",
    "\n",
    "But that might not be straightforward since the comparisons are dependent on prior results. \n",
    "Maybe vectorization is more effective in finding the min within a block without considering \n",
    "prior elements.\n",
    "\n",
    "Wait, no—selection sort for each position i finds the minimum from i to n-1 and swaps it with \n",
    "A[i]. So if I can vectorize the process of finding the minimum in a block starting at i, that \n",
    "part could be sped up.\n",
    "\n",
    "So perhaps for each i, load 8 elements starting at i into a vector. Then within this vector, \n",
    "find the index of the smallest element (relative to the other 7). Then, among these 8, if the \n",
    "smallest is actually the global minimum from i onwards, then it can be placed in A[i]. But \n",
    "that doesn't directly work because the min could be anywhere beyond i.\n",
    "\n",
    "Wait, maybe I'm overcomplicating. Let's think of a simpler approach: for each group of 8 \n",
    "elements, find their indices and keep track of the overall minimum as we go.\n",
    "\n",
    "But then again, that might require scalar operations to update the overall min index, which \n",
    "isn't vectorizable.\n",
    "\n",
    "Alternatively, perhaps process the array in chunks where each chunk is 64 bytes (8 doubles), \n",
    "and within each chunk, perform vectorized comparisons. But I'm not sure how that would fit \n",
    "into the selection sort logic.\n",
    "\n",
    "Maybe it's better to first implement the helper function for finding the min index within a \n",
    "vector of 8 elements. Then, use that in the selection sort loop.\n",
    "\n",
    "So, here's a rough plan:\n",
    "\n",
    "1. For each i from 0 to n-1:\n",
    "   a. Load 8 doubles starting at i into a vector.\n",
    "   b. Find the index (within these 8) of the minimum double.\n",
    "   c. Compare this with the current min index if there are multiple groups. Hmm, but how?\n",
    "\n",
    "Wait, maybe I need to process each group independently and then handle the swapping.\n",
    "\n",
    "Alternatively, perhaps for each group starting at i, j = i + min_index_in_group, and then swap \n",
    "A[i] with A[j]. But that's not correct because the minimum in the group might be beyond the \n",
    "current i. So this approach would only find the minimum within the next 8 elements but not \n",
    "necessarily the actual global minimum.\n",
    "\n",
    "Hmm, perhaps I need to rethink the approach. Since selection sort relies on finding the global \n",
    "minimum each time, vectorization isn't straightforward because the min can be anywhere in the \n",
    "unsorted portion.\n",
    "\n",
    "Maybe a better way is to process multiple groups at once and find the minimum across all of \n",
    "them using vectors. For example, for i = 0 to n step 64:\n",
    "\n",
    "1. Load two vectors: from i and i+32 (each 8 elements).\n",
    "2. Find the min in each vector.\n",
    "3. Compare these two mins and determine which is smaller.\n",
    "4. Then, the global min index is either in the first or second half.\n",
    "\n",
    "But that still might require multiple steps and comparisons, which could be done with vectors \n",
    "but would complicate the code.\n",
    "\n",
    "Alternatively, perhaps it's better to stick with scalar operations for selection sort, as the \n",
    "vectorization may not provide significant speedups due to the algorithm's nature. But since \n",
    "the user specifically asked for an AVX512 version, I need to at least attempt a vectorized \n",
    "approach.\n",
    "\n",
    "Another idea: Use vector shuffles and compares to find the min in a block, then move that \n",
    "element into place using vector stores. For example:\n",
    "\n",
    "- Load 8 elements into a vector.\n",
    "- Compare all pairs to find the smallest, keeping track of the index.\n",
    "- Once the min is found, extract its value and position.\n",
    "- Then, perform a swap with the current i-th element.\n",
    "\n",
    "But I'm not sure how efficient this would be compared to scalar operations. Maybe the \n",
    "vectorized min finding is faster than scalar loops, but moving elements around might still \n",
    "require some scalar steps.\n",
    "\n",
    "Alternatively, perhaps for each group of 8, find the min index within that group and then use \n",
    "a gather operation to bring all those mins into a single vector for comparison across groups. \n",
    "But this seems complicated.\n",
    "\n",
    "I think I'll proceed with writing a helper function using AVX512 intrinsics to find the \n",
    "minimum in a block of 8 elements and its index, then integrate that into the selection sort \n",
    "loop.\n",
    "\n",
    "Wait, but how do I handle the index correctly? Because each vector has indices relative to \n",
    "their starting point. So if I have a vector loaded from i, the min index within the vector is \n",
    "offset by i. Then, when comparing with other vectors, I can determine which overall index is \n",
    "smaller.\n",
    "\n",
    "Hmm, perhaps in code:\n",
    "\n",
    "For i from 0 to n-8 step 8:\n",
    "   vec = _mm512_loadu_pd(arr + i);\n",
    "   min_val = find_min_in_vector(vec);\n",
    "   min_index = ... // how?\n",
    "\n",
    "Wait, the find_min_in_vector function would need to return both the minimum value and its \n",
    "index within the vector. But I'm not sure if there's an intrinsic for that.\n",
    "\n",
    "Alternatively, I can manually compare each element in the vector using shuffles and compares.\n",
    "\n",
    "For example:\n",
    "\n",
    "__m512d min_vec = vec;\n",
    "int min_index = 0;\n",
    "\n",
    "for (int j = 1; j < 8; j++) {\n",
    "   __m512d a = _mm512_maskload_pd(arr + i, 0x01); // first element\n",
    "   __m512d b = _mm512_maskload_pd(arr + i + j, 0x01);\n",
    "   if (j == 0) {\n",
    "       min_vec = a;\n",
    "       min_index = 0;\n",
    "   } else {\n",
    "       if (_mm512_cmp_pd(a, min_vec, ...)) {\n",
    "           min_vec = a;\n",
    "           min_index = j;\n",
    "       }\n",
    "   }\n",
    "}\n",
    "\n",
    "Wait, but this is still scalar code inside the vector loop. Maybe it's not efficient.\n",
    "\n",
    "Alternatively, perhaps I can use horizontal compares and find the index.\n",
    "\n",
    "But I'm getting stuck here. Maybe it's better to proceed with writing the code as per the \n",
    "initial plan, even if it's not optimal.\n",
    "\n",
    "So, putting it all together:\n",
    "\n",
    "The selection sort would have a loop for each element i from 0 to n-1.\n",
    "\n",
    "Inside that loop, we find the minimum in the subarray from i to n-1. To vectorize this, \n",
    "perhaps process multiple elements at once.\n",
    "\n",
    "But I'm not sure how to proceed further without more detailed knowledge of AVX512 \n",
    "instructions.\n",
    "\n",
    "Perhaps another approach is to precompute all possible min indices for each block and then \n",
    "handle the swapping.\n",
    "\n",
    "Alternatively, maybe it's better to use scalar operations for finding the min, but vectorize \n",
    "other parts, like moving elements around after finding the min.\n",
    "\n",
    "Wait, perhaps after finding the min index j in the subarray, we can load the entire block from \n",
    "i to i+7 into a vector and then replace A[i] with A[j], but that would require shifting \n",
    "elements, which isn't straightforward with vectors.\n",
    "\n",
    "Hmm, this is getting complicated. Maybe it's better to proceed with writing scalar code for \n",
    "selection sort and then see if any parts can be vectorized.\n",
    "\n",
    "Alternatively, perhaps use the fact that in AVX512, we can load multiple elements, compare \n",
    "them, and then extract the min index using bit operations.\n",
    "\n",
    "But I'm not sure about the exact instructions needed. Maybe looking up some examples would \n",
    "help, but since I'm doing this theoretically, I'll proceed carefully.\n",
    "\n",
    "In conclusion, while vectorizing selection sort with AVX512 is challenging due to its \n",
    "algorithmic nature, it's possible to find the minimum within a block using vectors and then \n",
    "perform necessary swaps. However, significant code complexity may arise, especially in \n",
    "managing indices and ensuring correctness across all iterations.\n",
    "## /think\n",
    "\n",
    "To implement an optimized version of selection sort using AVX512 vectorization, we can \n",
    "leverage vector operations to speed up the process of finding the minimum element in each \n",
    "segment of the array. Here's a high-level explanation of how this approach works:\n",
    "\n",
    "### Approach\n",
    "1. **Segmentation**: Divide the array into segments that fit into the vector width (64 bytes \n",
    "for AVX512, which can hold 8 double-precision numbers).\n",
    "2. **Vectorization of Minimum Search**: For each segment, use vector operations to find the \n",
    "minimum value and its index within that segment.\n",
    "3. **Swapping with Vector Operations**: Once the minimum is found, swap it into place using \n",
    "vector loads and stores to minimize scalar operations.\n",
    "\n",
    "### Solution Code\n",
    "```c\n",
    "#include <immintrin.h> // AVX512 intrinsics\n",
    "\n",
    "void avx512_selection_sort(double *arr, int n) {\n",
    "    for (int i = 0; i < n; ++i) {\n",
    "        // Find the minimum in the subarray from i to n-1\n",
    "        int min_index = i;\n",
    "        double min_val = arr[i];\n",
    "        \n",
    "        // Process the array in chunks of 8 elements\n",
    "        for (int j = i + 8; j <= n; j += 8) {\n",
    "            __m512d vec = _mm512_loadu_pd(arr + j - 8);\n",
    "            \n",
    "            // Compare each element in the vector to find the minimum\n",
    "            int mask;\n",
    "            for (int k = 0; k < 8; ++k) {\n",
    "                if (k == 0 || _mm512_cmp_pd_mask(\n",
    "                    _mm512_shuffle_pd(vec, vec, (k << 4)), \n",
    "                    min_val, _CMP_LT_OS)) {\n",
    "                    // Update the minimum value and index\n",
    "                    min_val = _mm512_shuffle_pd(vec, vec, (k << 4));\n",
    "                    min_index = j - 8 + k;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        // Swap the found minimum with the element at position i using vector operations\n",
    "        if (min_index != i) {\n",
    "            __m512d min_vec = _mm512_maskload_pd(arr, 0x01 << i);\n",
    "            __m512d current_vec = _mm512_loadu_pd(arr + i, 8);\n",
    "            \n",
    "            // Replace the ith element with the minimum value\n",
    "            _mm512_maskstore_pd(arr, 0x01 << i, min_vec);\n",
    "            \n",
    "            // Shift all elements from min_index to i-1 one position to the right\n",
    "            if (min_index > i) {\n",
    "                _mm512d vec = _mm512_loadu_pd(arr + i + 1, min_index - i - 1);\n",
    "                _mm512_storeu_pd(arr + i, vec);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Explanation\n",
    "- **Segmentation**: The array is processed in chunks of 8 elements at a time to fit within the \n",
    "AVX512 vector width.\n",
    "- **Finding Minimum**: For each segment, we use vector operations to compare all elements and \n",
    "find the minimum value efficiently. This involves shuffling elements into positions for \n",
    "comparison and updating the minimum index accordingly.\n",
    "- **Swapping**: Once the minimum is identified, it is moved into place using vector loads and \n",
    "stores, which can be more efficient than scalar operations.\n",
    "\n",
    "This approach significantly reduces the number of scalar operations by utilizing vector \n",
    "instructions to handle multiple elements simultaneously, leading to improved performance \n",
    "compared to a standard selection sort."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
